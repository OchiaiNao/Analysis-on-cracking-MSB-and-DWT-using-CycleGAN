{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from itertools import cycle\n",
    "from PIL import Image\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.transforms import ToTensor\n",
    "import numpy as np\n",
    "import torchvision.utils as vutils\n",
    "import pywt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageFolder(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.dataset = ImageFolder(root_dir, transform=transform)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, _ = self.dataset[idx]\n",
    "        file_path = self.dataset.imgs[idx][0]\n",
    "        file_name = os.path.basename(file_path)\n",
    "        return image, file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.InstanceNorm2d(in_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.InstanceNorm2d(in_channels),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, num_res_blocks=6):\n",
    "        super(Generator, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "         # Create a list of residual blocks with the specified number of blocks\n",
    "        res_blocks = [ResidualBlock(256) for _ in range(num_res_blocks)]\n",
    "        # Convert the list of residual blocks to a sequential model\n",
    "        self.residual_blocks = nn.Sequential(*res_blocks)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder-decoder forward pass\n",
    "        x = self.encoder(x)\n",
    "        x = self.residual_blocks(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PatchGAN Discriminator class\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.InstanceNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(512, 1, kernel_size=3, stride=1, padding=1),\n",
    "        )\n",
    "    # Implement the forward pass by passing the input through the layers and reshaping the output\n",
    "    def forward(self, x):\n",
    "        return self.layers(x).view(x.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dwt_embed(cover_image, secret_image):\n",
    "    device = cover_image.device\n",
    "    \n",
    "    # Convert the cover and secret images from PyTorch tensors to NumPy arrays\n",
    "    cover_image_np = tensor_to_np(cover_image.cpu())\n",
    "    secret_image_np = tensor_to_np(secret_image.cpu())\n",
    "    \n",
    "    # Compute the DWT coefficients for the cover and secret images using the Haar wavelet\n",
    "    cover_coeffs = pywt.dwt2(cover_image_np, 'haar')\n",
    "    secret_coeffs = pywt.dwt2(secret_image_np, 'haar')\n",
    "    \n",
    "    # Encoding here:\n",
    "    # Combine the coefficients of the cover and secret images\n",
    "    stego_coeffs = (cover_coeffs[0] + secret_coeffs[0], cover_coeffs[1])\n",
    "    \n",
    "    # Compute the inverse DWT to obtain the stego image\n",
    "    stego_image_np = pywt.idwt2(stego_coeffs, 'haar').clip(0, 255).astype(np.uint8)\n",
    "    \n",
    "    # Return tensors\n",
    "    return np_to_tensor(stego_image_np, device)\n",
    "\n",
    "\n",
    "def dwt_extract(stego_image, cover_image):\n",
    "    device = stego_image.device\n",
    "    \n",
    "    # Convert the stego and cover images from PyTorch tensors to NumPy arrays\n",
    "    stego_image_np = tensor_to_np(stego_image.cpu())\n",
    "    cover_image_np = tensor_to_np(cover_image.cpu())\n",
    "    \n",
    "    # Compute the DWT coefficients for the stego and cover images using the Haar wavelet\n",
    "    stego_coeffs = pywt.dwt2(stego_image_np, 'haar')\n",
    "    cover_coeffs = pywt.dwt2(cover_image_np, 'haar')\n",
    "    \n",
    "    # Decoding here:\n",
    "    # Calculate the hidden image coefficients by subtracting the cover coefficients from the stego coefficients\n",
    "    secret_coeffs = (stego_coeffs[0] - cover_coeffs[0], cover_coeffs[1])\n",
    "    \n",
    "    # Compute the inverse DWT to obtain the hidden image\n",
    "    secret_image_np = pywt.idwt2(secret_coeffs, 'haar').clip(0, 255).astype(np.uint8)\n",
    "    \n",
    "    # Return tensors\n",
    "    return np_to_tensor(secret_image_np, device)\n",
    "\n",
    "def tensor_to_np(tensor):\n",
    "    return tensor.detach().cpu().numpy()\n",
    "\n",
    "def np_to_tensor(array, device):\n",
    "    return torch.tensor(array, device=device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_file_name(file_name):\n",
    "    underscore_pos = file_name.index(\")_\")\n",
    "    return file_name[:underscore_pos+1] + '.jpg', file_name[underscore_pos+2:]\n",
    "\n",
    "def get_tensor_by_name(file_name, tensor_dict):\n",
    "    return tensor_dict.get(file_name, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(generator_H2S, generator_S2H,\n",
    "          discriminator_H, discriminator_S,\n",
    "          cover_loader, stego_loader, hidden_loader,\n",
    "          val_cover_loader, val_stego_loader, val_hidden_loader, device, \n",
    "          optimizer_G,\n",
    "          optimizer_H, optimizer_S, \n",
    "          num_epochs, flag):\n",
    "    \n",
    "    \"\"\"\n",
    "    Train function for the cycle_GAN model.\n",
    "\n",
    "    Parameters:\n",
    "    - generator_H2S (nn.Module): The generator model that transforms hidden images to stego images.\n",
    "    - generator_S2H (nn.Module): The generator model that transforms stego images to hidden images.\n",
    "    - discriminator_H (nn.Module): The discriminator model that discriminates between real and fake hidden images.\n",
    "    - discriminator_S (nn.Module): The discriminator model that discriminates between real and fake stego images.\n",
    "    - cover_loader (DataLoader): DataLoader for cover images.\n",
    "    - stego_loader (DataLoader): DataLoader for stego images.\n",
    "    - hidden_loader (DataLoader): DataLoader for hidden images.\n",
    "    - val_cover_loader (DataLoader): DataLoader for validation cover images.\n",
    "    - val_stego_loader (DataLoader): DataLoader for validation stego images.\n",
    "    - val_hidden_loader (DataLoader): DataLoader for validation hidden images.\n",
    "    - device (torch.device): Device to perform computations on (CPU or GPU).\n",
    "    - optimizer_G (torch.optim.Optimizer): Optimizer for both generator models (generator_H2S and generator_S2H).\n",
    "    - optimizer_H (torch.optim.Optimizer): Optimizer for the discriminator_H model.\n",
    "    - optimizer_S (torch.optim.Optimizer): Optimizer for the discriminator_S model.\n",
    "    - num_epochs (int): The number of epochs to train the model.\n",
    "    - flag (int): Flag to check where the save should start (flag+epoch).\n",
    "    \"\"\"\n",
    "    cover_tensor_dict = {}\n",
    "    hidden_tensor_dict = {}\n",
    "    for image_tensor, file_name in cover_loader:\n",
    "        cover_tensor_dict[file_name[0]] = image_tensor\n",
    "    for image_tensor, file_name in hidden_loader:\n",
    "        hidden_tensor_dict[file_name[0]] = image_tensor\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for stego in stego_loader:\n",
    "            stego_img, stego_name = stego\n",
    "            cover_name, hidden_name = split_file_name(stego_name[0])\n",
    "            cover_img = get_tensor_by_name(cover_name, cover_tensor_dict)\n",
    "            hidden_img = get_tensor_by_name(hidden_name, hidden_tensor_dict)\n",
    "\n",
    "            # Move images to device\n",
    "            stego_img = stego_img.to(device)\n",
    "            cover_img = stego_img.to(device)\n",
    "            hidden_img = hidden_img.to(device)\n",
    "\n",
    "            # --------------------\n",
    "            # Train the generators\n",
    "            # --------------------\n",
    "            \n",
    "            # Identity loss\n",
    "            same_hidden = generator_S2H(hidden_img)\n",
    "            loss_identity_H = criterion_cycle(same_hidden, hidden_img) * 5.0\n",
    "            \n",
    "            same_stego = generator_H2S(stego_img)\n",
    "            loss_identity_S = criterion_cycle(same_stego, stego_img) * 5.0\n",
    "\n",
    "            # GAN loss\n",
    "            fake_hidden = generator_S2H(stego_img)\n",
    "            pred_fake_hidden = discriminator_H(fake_hidden)\n",
    "            loss_gan_S2H = criterion_gan(pred_fake_hidden, torch.ones_like(pred_fake_hidden))\n",
    "\n",
    "            fake_stego = generator_H2S(hidden_img)\n",
    "            pred_fake_stego = discriminator_S(fake_stego)\n",
    "            loss_gan_H2S = criterion_gan(pred_fake_stego, torch.ones_like(pred_fake_stego))\n",
    "\n",
    "            # Cycle loss\n",
    "            \n",
    "            # Use dwt_embed to recover stego image\n",
    "            recovered_stego = generator_H2S(fake_hidden)\n",
    "            dwt_recovered_stego = dwt_embed(cover_img, fake_hidden)\n",
    "            loss_cycle_S = criterion_cycle(recovered_stego, dwt_recovered_stego) * 10.0\n",
    "            \n",
    "            # Use dwt_extract to recover hidden image\n",
    "            recovered_hidden = generator_S2H(fake_stego)\n",
    "            dwt_recovered_hidden = dwt_extract(fake_stego, cover_img)\n",
    "            loss_cycle_H = criterion_cycle(recovered_hidden, dwt_recovered_hidden) * 10.0\n",
    "\n",
    "            # Total generator loss\n",
    "            total_g_loss = loss_identity_H + loss_identity_S + loss_gan_S2H + loss_gan_H2S + loss_cycle_S + loss_cycle_H\n",
    "            total_g_loss.backward()\n",
    "            \n",
    "            optimizer_G.step()\n",
    "            \n",
    "            # ------------------------\n",
    "            # Train the discriminators\n",
    "            # ------------------------\n",
    "            \n",
    "            optimizer_H.zero_grad()\n",
    "            optimizer_S.zero_grad()\n",
    "            \n",
    "            # Discriminator S\n",
    "            \n",
    "            # Real loss\n",
    "            pred_real_stego = discriminator_S(stego_img)\n",
    "            loss_d_real_stego = criterion_gan(pred_real_stego, torch.ones_like(pred_real_stego))\n",
    "\n",
    "            # Fake loss\n",
    "            fake_stego.detach_()\n",
    "            pred_fake_stego = discriminator_S(fake_stego)\n",
    "            loss_d_fake_stego = criterion_gan(pred_fake_stego, torch.zeros_like(pred_fake_stego))\n",
    "\n",
    "            # Total Discriminator S loss\n",
    "            total_d_s_loss = (loss_d_real_stego + loss_d_fake_stego) * 0.5\n",
    "            total_d_s_loss.backward()\n",
    "\n",
    "            optimizer_S.step()\n",
    "            \n",
    "            # Discriminator H\n",
    "            \n",
    "            # Real loss\n",
    "            pred_real_hidden = discriminator_H(hidden_img)\n",
    "            loss_d_real_hidden = criterion_gan(pred_real_hidden, torch.ones_like(pred_real_hidden))\n",
    "\n",
    "            # Fake loss\n",
    "            fake_hidden.detach_()\n",
    "            pred_fake_hidden = discriminator_H(fake_hidden)\n",
    "            loss_d_fake_hidden = criterion_gan(pred_fake_hidden, torch.zeros_like(pred_fake_hidden))\n",
    "\n",
    "            # Total Discriminator H loss\n",
    "            total_d_h_loss = (loss_d_real_hidden + loss_d_fake_hidden) * 0.5\n",
    "            total_d_h_loss.backward()\n",
    "            \n",
    "            optimizer_H.step()\n",
    "\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] | Generator Loss: {total_g_loss.item():.4f} | Discriminator S Loss: {total_d_s_loss.item():.4f} | Discriminator H Loss: {total_d_h_loss.item():.4f}\")\n",
    "\n",
    "        # Save the model checkpoints every 50 epochs\n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            torch.save(generator_H2S.state_dict(), f'./model_params/DWT/H2S/generator_H2S_epoch_{flag+epoch+1}.pth')\n",
    "            torch.save(generator_S2H.state_dict(), f'./model_params/DWT/S2H/generator_S2H_epoch_{flag+epoch+1}.pth')\n",
    "            torch.save(discriminator_H.state_dict(), f'./model_params/DWT/DH/discriminator_H_epoch_{flag+epoch+1}.pth')\n",
    "            torch.save(discriminator_S.state_dict(), f'./model_params/DWT/DS/discriminator_S_epoch_{flag+epoch+1}.pth')\n",
    "            torch.save(optimizer_G.state_dict(), f'./model_params/DWT/optimizer/G/optimizer_G_{flag+epoch+1}.pth')\n",
    "            torch.save(optimizer_H.state_dict(), f'./model_params/DWT/optimizer/H/optimizer_H_{flag+epoch+1}.pth')\n",
    "            torch.save(optimizer_S.state_dict(), f'./model_params/DWT/optimizer/S/optimizer_S_{flag+epoch+1}.pth')\n",
    "        # Valid the model every 10 epochs\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            generator_H2S.eval()\n",
    "            generator_S2H.eval()\n",
    "            discriminator_H.eval()\n",
    "            discriminator_S.eval()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for val_cover, val_stego, val_hidden in zip(val_cover_loader, val_stego_loader, val_hidden_loader):\n",
    "                    val_cover_img, _ = val_cover\n",
    "                    val_stego_img, _ = val_stego\n",
    "                    val_hidden_img, _ = val_hidden\n",
    "\n",
    "                    val_cover_img = val_cover_img.to(device)\n",
    "                    val_stego_img = val_stego_img.to(device)\n",
    "                    val_hidden_img = val_hidden_img.to(device)\n",
    "\n",
    "                    fake_hidden = generator_S2H(val_stego_img)\n",
    "                    fake_stego = generator_H2S(val_hidden_img)\n",
    "                    recovered_hidden = generator_S2H(fake_stego)\n",
    "                    recovered_stego = generator_H2S(fake_hidden)\n",
    "\n",
    "                    val_g_loss = criterion_cycle(recovered_hidden, val_hidden_img) + criterion_cycle(recovered_stego, val_stego_img)\n",
    "                    val_d_h_loss = criterion_gan(discriminator_H(val_hidden_img), torch.ones_like(discriminator_H(val_hidden_img))) + criterion_gan(discriminator_H(fake_hidden.detach()), torch.zeros_like(discriminator_H(fake_hidden.detach())))\n",
    "                    val_d_s_loss = criterion_gan(discriminator_S(val_stego_img), torch.ones_like(discriminator_S(val_stego_img))) + criterion_gan(discriminator_S(fake_stego.detach()), torch.zeros_like(discriminator_S(fake_stego.detach())))\n",
    "                    \n",
    "            generator_H2S.train()\n",
    "            generator_S2H.train()\n",
    "            discriminator_H.train()\n",
    "            discriminator_S.train()\n",
    "            print(f\"Validation | Generator Loss: {val_g_loss.item():.4f} | Discriminator S Loss: {val_d_s_loss.item():.4f} | Discriminator H Loss: {val_d_h_loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda')\n",
    "\n",
    "# Load the datasets\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((96, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "# Train set\n",
    "dataset_cover =CustomImageFolder('./train/cover', transform=transform)\n",
    "dataset_stego = CustomImageFolder('./train/stego', transform=transform)\n",
    "dataset_hidden = CustomImageFolder('./train/hidden', transform=transform)\n",
    "\n",
    "cover_loader = DataLoader(dataset_cover, batch_size=1)\n",
    "stego_loader = DataLoader(dataset_stego, batch_size=1)\n",
    "hidden_loader = DataLoader(dataset_hidden, batch_size=1)\n",
    "\n",
    "# Val set\n",
    "dataset_cover_val = CustomImageFolder('./valid/cover', transform=transform)\n",
    "dataset_stego_val = CustomImageFolder('./valid/stego', transform=transform)\n",
    "dataset_hidden_val = CustomImageFolder('./valid/hidden', transform=transform)\n",
    "\n",
    "val_cover_loader = DataLoader(dataset_cover_val, batch_size=1)\n",
    "val_stego_loader = DataLoader(dataset_stego_val, batch_size=1)\n",
    "val_hidden_loader = DataLoader(dataset_hidden_val, batch_size=1)\n",
    "\n",
    "# Test set\n",
    "dataset_cover_test = CustomImageFolder('./test/cover', transform=transform)\n",
    "dataset_stego_test = CustomImageFolder('./test/stego', transform=transform)\n",
    "dataset_hidden_test = CustomImageFolder('./test/hidden', transform=transform)\n",
    "\n",
    "test_cover_loader = DataLoader(dataset_cover_test, batch_size=1)\n",
    "test_stego_loader = DataLoader(dataset_stego_test, batch_size=1)\n",
    "test_hidden_loader = DataLoader(dataset_hidden_test, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the generators and discriminators\n",
    "generator_H2S = Generator()\n",
    "generator_S2H = Generator()\n",
    "\n",
    "discriminator_H = Discriminator()\n",
    "discriminator_S = Discriminator()\n",
    "\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "generator_H2S.to(device)\n",
    "generator_S2H.to(device)\n",
    "\n",
    "discriminator_H.to(device)\n",
    "discriminator_S.to(device)\n",
    "\n",
    "\n",
    "# Define the optimizers\n",
    "optimizer_G = optim.Adam(list(generator_H2S.parameters()) + list(generator_S2H.parameters()), lr=0.0005, betas=(0.5, 0.999))\n",
    "\n",
    "optimizer_H = optim.Adam(discriminator_H.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
    "optimizer_S = optim.Adam(discriminator_S.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
    "\n",
    "\n",
    "# Define the loss functions\n",
    "criterion_gan = torch.nn.MSELoss()\n",
    "criterion_cycle = torch.nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300] | Generator Loss: 6.2407 | Discriminator S Loss: 0.0000 | Discriminator H Loss: 0.0000\n",
      "Epoch [2/300] | Generator Loss: 6.1600 | Discriminator S Loss: 0.0000 | Discriminator H Loss: 0.0000\n",
      "Epoch [3/300] | Generator Loss: 6.4495 | Discriminator S Loss: 0.0000 | Discriminator H Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "train(generator_H2S, generator_S2H, discriminator_H, discriminator_S,\n",
    "      cover_loader, stego_loader, hidden_loader, val_cover_loader, val_stego_loader, val_hidden_loader, device, optimizer_G, optimizer_H, optimizer_S, num_epochs=300, flag=700)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_hidden_image(generator_H2S, generator_S2H, cover_image, hidden_image):\n",
    "    device = cover_image.device\n",
    "    # Real stego image\n",
    "    stego_image = dwt_embed(cover_image, hidden_image)\n",
    "\n",
    "    # Reconstructed hidden image\n",
    "    reconstructed_hidden_image = generator_S2H(stego_image.to(device)).detach()\n",
    "    \n",
    "    return reconstructed_hidden_image.cpu()\n",
    "\n",
    "def load_saved_dicts(generator_H2S, generator_S2H, discriminator_S, discriminator_H, optimizer_G, optimizer_S, optimizer_H, flag):\n",
    "    # Save the model state_dict\n",
    "    generator_H2S.load_state_dict(torch.load(f'./model_params/DWT/H2S/generator_H2S_epoch_{flag}.pth'))\n",
    "    generator_S2H.load_state_dict(torch.load(f'./model_params/DWT/S2H/generator_S2H_epoch_{flag}.pth'))\n",
    "    discriminator_S.load_state_dict(torch.load(f'./model_params/DWT/DS/discriminator_S_epoch_{flag}.pth'))\n",
    "    discriminator_H.load_state_dict(torch.load(f'./model_params/DWT/DH/discriminator_H_epoch_{flag}.pth'))\n",
    "    # Also optimizers\n",
    "    optimizer_G.load_state_dict(torch.load(f'./model_params/DWT/optimizer/G/optimizer_G_{flag}.pth'))\n",
    "    optimizer_S.load_state_dict(torch.load(f'./model_params/DWT/optimizer/S/optimizer_S_{flag}.pth'))\n",
    "    optimizer_H.load_state_dict(torch.load(f'./model_params/DWT/optimizer/H/optimizer_H_{flag}.pth'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_hidden_images(generator_H2S, generator_S2H, test_cover_loader, test_stego_loader, output_dir, flag):\n",
    "    to_pil_image = transforms.ToPILImage()\n",
    "    \n",
    "    for i, (cover_data, stego_data) in enumerate(zip(test_cover_loader, test_stego_loader)):\n",
    "        cover_image_tensor, _ = cover_data\n",
    "        stego_image_tensor, _ = stego_data\n",
    "        \n",
    "        # Move tensors to the appropriate device\n",
    "        device = torch.device(\"cuda\")\n",
    "        cover_image_tensor = cover_image_tensor.to(device)\n",
    "        stego_image_tensor = stego_image_tensor.to(device)\n",
    "        \n",
    "        # Reconstruct the hidden image\n",
    "        reconstructed_hidden_image = reconstruct_hidden_image(generator_H2S, generator_S2H, cover_image_tensor, stego_image_tensor)\n",
    "        \n",
    "        # Convert the reconstructed hidden image back to a PIL Image\n",
    "        reconstructed_hidden_image_pil = to_pil_image(reconstructed_hidden_image.squeeze(0))\n",
    "        \n",
    "        # Save the reconstructed hidden image\n",
    "        output_path = os.path.join(output_dir, f\"{flag}/{i}.png\")\n",
    "        reconstructed_hidden_image_pil.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This area is for initialing and load the saved model\n",
    "\n",
    "# Instantiate the generators and discriminators\n",
    "generator_H2S = Generator()\n",
    "generator_S2H = Generator()\n",
    "\n",
    "\n",
    "discriminator_S = Discriminator()\n",
    "discriminator_H = Discriminator()\n",
    "\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "generator_H2S.to(device)\n",
    "generator_S2H.to(device)\n",
    "\n",
    "discriminator_H.to(device)\n",
    "discriminator_S.to(device)\n",
    "\n",
    "\n",
    "# Define the optimizers\n",
    "optimizer_G = optim.Adam(list(generator_H2S.parameters()) + list(generator_S2H.parameters()), lr=0.0005, betas=(0.5, 0.999))\n",
    "\n",
    "\n",
    "optimizer_S = optim.Adam(discriminator_S.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_H = optim.Adam(discriminator_H.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "# Define the loss functions\n",
    "criterion_gan = torch.nn.MSELoss()\n",
    "criterion_cycle = torch.nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_lr(optimizer_G, optimizer_H, optimizer_S, flag):\n",
    "    # change learning rate to specific value\n",
    "    optimizer_G_state_dict = torch.load(f'./model_params/DWT/optimizer/G/optimizer_G_{flag}.pth')\n",
    "    optimizer_H_state_dict = torch.load(f'./model_params/DWT/optimizer/H/optimizer_H_{flag}.pth')\n",
    "    optimizer_S_state_dict = torch.load(f'./model_params/DWT/optimizer/S/optimizer_S_{flag}.pth')\n",
    "    \n",
    "    optimizer_G_state_dict['param_groups'][0]['lr'] = 0.001\n",
    "    optimizer_H_state_dict['param_groups'][0]['lr'] = 0.00001\n",
    "    optimizer_S_state_dict['param_groups'][0]['lr'] = 0.00001\n",
    "\n",
    "    optimizer_G.load_state_dict(optimizer_G_state_dict)\n",
    "    optimizer_H.load_state_dict(optimizer_H_state_dict)\n",
    "    optimizer_S.load_state_dict(optimizer_S_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct\n",
    "flag = 500\n",
    "output_dir = './reconstructed_hidden/DWT/'\n",
    "\n",
    "load_saved_dicts(generator_H2S, generator_S2H, discriminator_S, discriminator_H, optimizer_G, optimizer_S, optimizer_H, flag=flag)\n",
    "\n",
    "# change lr at epoch 1000\n",
    "# change_lr(optimizer_G, optimizer_C, optimizer_S, flag=flag)\n",
    "\n",
    "flag = 500\n",
    "# reconstruct at epoch flag\n",
    "reconstruct_hidden_images(generator_H2S, generator_S2H, test_cover_loader, test_stego_loader, output_dir, flag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
