{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, num_residual_blocks=6):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        # Define encoder layers\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 128, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 256, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Define residual layers\n",
    "        self.residuals = nn.Sequential(\n",
    "            *[ResidualBlock(256) for _ in range(num_residual_blocks)]\n",
    "        )\n",
    "        \n",
    "        # Define decoder layers\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 3, 3, stride=1, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Apply encoder layers\n",
    "        x = self.encoder(x)\n",
    "        \n",
    "        # Apply residual layers\n",
    "        x = self.residuals(x)\n",
    "        \n",
    "        # Apply decoder layers\n",
    "        x = self.decoder(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(channels, channels, 3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(channels, channels, 3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        \n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        # Define discriminator layers\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 256, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(256, 512, 4, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(512, 1, 4, stride=1, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lswt_steganography_encode(cover_freq, secret_freq, alpha=0.1):\n",
    "    coeffs_cover = cover_freq.reshape((1, 1, *cover_freq.shape))\n",
    "    coeffs_secret = secret_freq.reshape((1, 1, *secret_freq.shape))\n",
    "    \n",
    "    secret_hf = coeffs_secret[0][0][1]\n",
    "    secret_mask = np.mean(secret_hf, axis=0)\n",
    "    \n",
    "    stego_hf = coeffs_cover[0][0][1] + alpha * secret_mask\n",
    "    stego_freq = np.zeros_like(coeffs_cover)\n",
    "    stego_freq[0][0][1] = stego_hf\n",
    "    \n",
    "    return stego_freq.reshape(cover_freq.shape)\n",
    "\n",
    "def lswt_steganography_decode(stego_freq, cover_freq, alpha=0.1):\n",
    "    coeffs_stego = stego_freq.reshape((1, 1, *stego_freq.shape))\n",
    "    coeffs_cover = cover_freq.reshape((1, 1, *cover_freq.shape))\n",
    "    \n",
    "    secret_hf = [(coeffs_stego[0][0][1][i] - coeffs_cover[0][0][1][i]) / alpha for i in range(3)]\n",
    "    secret_mask = np.mean(secret_hf, axis=0)\n",
    "    secret_freq = np.zeros_like(coeffs_cover)\n",
    "    secret_freq[0][0][1] = secret_mask\n",
    "    \n",
    "    return secret_freq.reshape(stego_freq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cycle_gan(g_AB, g_BA, d_A, d_B, opt_g, opt_d, criterion_gan, criterion_cycle, criterion_identity, \n",
    "                    dataloader_cover, dataloader_hidden, dataloader_stego, \n",
    "                    device, num_epochs):\n",
    "    alpha = 0.1\n",
    "    lambda_cycle = 10\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (cover_img, hidden_img, stego_img) in enumerate(zip(dataloader_cover, dataloader_hidden, dataloader_stego)):\n",
    "            # Set generator and discriminator gradients to zero\n",
    "            opt_g.zero_grad()\n",
    "            opt_d.zero_grad()\n",
    "            \n",
    "            # Move input data to device\n",
    "            cover, _ = cover_img\n",
    "            hidden, _ = hidden_img\n",
    "            stego, _ = stego_img\n",
    "            \n",
    "            cover = cover.to(device)\n",
    "            hidden = hidden.to(device)\n",
    "            stego = stego.to(device)\n",
    "            \n",
    "            # Generate fake images\n",
    "            fake_B = g_AB(stego)\n",
    "            fake_A = g_BA(hidden)\n",
    "            \n",
    "            # Compute cycle consistency loss\n",
    "            fake_stego = g_BA(hidden)\n",
    "            fake_hidden_freq = lswt_steganography_decode(fake_stego.detach().cpu().numpy()[0, 0], cover.cpu().numpy()[0, 0], alpha=alpha)\n",
    "            fake_hidden_freq = torch.from_numpy(fake_hidden_freq).unsqueeze(0).unsqueeze(0).float().to(device)\n",
    "            \n",
    "            fake_hidden = g_AB(stego)\n",
    "            fake_stego_freq = lswt_steganography_encode(fake_hidden.detach().cpu().numpy()[0, 0], cover.cpu().numpy()[0, 0], alpha=alpha)\n",
    "            fake_stego_freq = torch.from_numpy(fake_stego_freq).unsqueeze(0).unsqueeze(0).float().to(device)\n",
    "            \n",
    "            cycle_loss_B = criterion_cycle(fake_hidden_freq, fake_stego)\n",
    "            cycle_loss_A = criterion_cycle(fake_stego_freq, fake_hidden)\n",
    "            \n",
    "            # Train discriminators\n",
    "            real_A = d_A(hidden)\n",
    "            real_B = d_B(stego)\n",
    "            fake_A_ = d_A(fake_A.detach())\n",
    "            fake_B_ = d_B(fake_B.detach())\n",
    "            loss_d_A = criterion_gan(real_A, torch.ones_like(real_A)) + criterion_gan(fake_A_, torch.zeros_like(fake_A_))\n",
    "            loss_d_B = criterion_gan(real_B, torch.ones_like(real_B)) + criterion_gan(fake_B_, torch.zeros_like(fake_B_))\n",
    "            loss_d = (loss_d_A + loss_d_B) / 2\n",
    "            loss_d.backward()\n",
    "            opt_d.step()\n",
    "            \n",
    "            # Train generators\n",
    "            fake_A_ = d_A(fake_A)\n",
    "            fake_B_ = d_B(fake_B)\n",
    "            loss_gan_A = criterion_gan(fake_A_, torch.ones_like(fake_A_))\n",
    "            loss_gan_B = criterion_gan(fake_B_, torch.ones_like(fake_B_))\n",
    "            loss_g = (loss_gan_A + loss_gan_B) / 2 + lambda_cycle * (cycle_loss_B + cycle_loss_A) * 0.5\n",
    "            loss_g.backward()\n",
    "            opt_g.step()\n",
    "            \n",
    "        # Print progress\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] Loss G: {loss_g:.4f} Loss D_A: {loss_d_A:.4f} Loss D_B: {loss_d_B:.4f}\")\n",
    "\n",
    "        if (epoch+1) % 10 == 0:\n",
    "\n",
    "            torch.save({\n",
    "                'epoch': epoch+1,\n",
    "                'g_AB_state_dict': g_AB.state_dict(),\n",
    "                'g_BA_state_dict': g_BA.state_dict(),\n",
    "                'd_A_state_dict': d_A.state_dict(),\n",
    "                'd_B_state_dict': d_B.state_dict(),\n",
    "                'opt_g_state_dict': opt_g.state_dict(),\n",
    "                'opt_d_state_dict': opt_d.state_dict(),\n",
    "                'loss': loss_g,\n",
    "            }, f'./model_params/SWT/checkpoint_{num_epochs}.pth')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda')\n",
    "\n",
    "# Load the datasets\n",
    "\n",
    "transform_frequency = transforms.Compose([\n",
    "    transforms.Resize((96, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    lambda x: pywt.swt2(x.numpy(), 'bior1.1', level=1)[0][0],\n",
    "])\n",
    "\n",
    "# Train set\n",
    "dataset_cover = ImageFolder('./train/cover', transform=transform_frequency)\n",
    "dataset_stego = ImageFolder('./train/LSWT_stego', transform=transform_frequency)\n",
    "dataset_hidden = ImageFolder('./train/LSWT_hidden', transform=transform_frequency)\n",
    "\n",
    "cover_loader = DataLoader(dataset_cover, batch_size=1)\n",
    "stego_loader = DataLoader(dataset_stego, batch_size=1)\n",
    "hidden_loader = DataLoader(dataset_hidden, batch_size=1)\n",
    "\n",
    "# Test set\n",
    "dataset_cover_test = ImageFolder('./test/cover', transform=transform_frequency)\n",
    "dataset_stego_test = ImageFolder('./test/LSWT_stego', transform=transform_frequency)\n",
    "dataset_hidden_test = ImageFolder('./test/LSWT_hidden', transform=transform_frequency)\n",
    "\n",
    "test_cover_loader = DataLoader(dataset_cover_test, batch_size=1)\n",
    "test_stego_loader = DataLoader(dataset_stego_test, batch_size=1)\n",
    "test_hidden_loader = DataLoader(dataset_hidden_test, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the generators and discriminators\n",
    "g_AB = Generator().to(device)\n",
    "g_BA = Generator().to(device)\n",
    "d_A = Discriminator().to(device)\n",
    "d_B = Discriminator().to(device)\n",
    "\n",
    "# Define the optimizers\n",
    "opt_g = optim.Adam(list(g_AB.parameters()) + list(g_BA.parameters()), lr=0.0005, betas=(0.5, 0.999))\n",
    "opt_d = optim.Adam(list(d_A.parameters()) + list(d_B.parameters()), lr=0.00001, betas=(0.5, 0.999))\n",
    "\n",
    "# Define the loss functions\n",
    "criterion_gan = nn.MSELoss()\n",
    "criterion_cycle = nn.L1Loss()\n",
    "criterion_identity = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "train_cycle_gan(g_AB, g_BA, d_A, d_B, opt_g, opt_d, criterion_gan, criterion_cycle, criterion_identity,\n",
    "                cover_loader, hidden_loader, stego_loader,\n",
    "                device, num_epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(checkpoint_path, g_AB, g_BA, d_A, d_B, opt_g, opt_d):\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "    g_AB.load_state_dict(checkpoint['g_AB_state_dict'])\n",
    "    g_BA.load_state_dict(checkpoint['g_BA_state_dict'])\n",
    "    d_A.load_state_dict(checkpoint['d_A_state_dict'])\n",
    "    d_B.load_state_dict(checkpoint['d_B_state_dict'])\n",
    "    opt_g.load_state_dict(checkpoint['opt_g_state_dict'])\n",
    "    opt_d.load_state_dict(checkpoint['opt_d_state_dict'])\n",
    "\n",
    "    return checkpoint['epoch'], checkpoint['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch, loss = load_model(f'./model_params/SWT/checkpoint_500.pth', g_AB, g_BA, d_A, d_B, opt_g, opt_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import save_image\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision.transforms.functional import to_tensor\n",
    "\n",
    "def tensor_to_image(tensor):\n",
    "    # Perform inverse stationary wavelet transform (iswt2)\n",
    "    img_iswt = pywt.iswt2([(tensor.numpy(), None, None, None)], 'bior1.1')\n",
    "    \n",
    "    # Convert the image back to the PIL format\n",
    "    img_pil = Image.fromarray(np.uint8(img_iswt * 255), mode='L')\n",
    "    \n",
    "    return img_pil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 1 at dim 1 (got 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-a046d4fac00e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0minput_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./test/LSWT_stego/class1'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0moutput_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./output_images/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mreconstruct_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_BA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-49-a046d4fac00e>\u001b[0m in \u001b[0;36mreconstruct_images\u001b[0;34m(input_dir, output_dir, g_BA, device)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;31m# Load the image and apply the same transformation as in the dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mimg_frequency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform_frequency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;31m# Generate hidden images using G_BA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: expected sequence of length 1 at dim 1 (got 3)"
     ]
    }
   ],
   "source": [
    "transform_frequency = transforms.Compose([\n",
    "    transforms.Resize((96, 128)),\n",
    "    lambda x: pywt.swt2(to_tensor(x).numpy(), 'bior1.1', level=1)[0],\n",
    "])\n",
    "\n",
    "def reconstruct_images(input_dir, output_dir, g_BA, device):\n",
    "    # Ensure the output directory exists\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Read and process images from the input directory\n",
    "    for file in os.listdir(input_dir):\n",
    "        if file.endswith(('.jpg', '.png', '.jpeg')):\n",
    "            file_path = os.path.join(input_dir, file)\n",
    "            \n",
    "            # Load the image and apply the same transformation as in the dataloader\n",
    "            img = Image.open(file_path)\n",
    "            img_frequency = torch.tensor(transform_frequency(img), dtype=torch.float32).to(device)\n",
    "            \n",
    "            # Generate hidden images using G_BA\n",
    "            with torch.no_grad():\n",
    "                img_hidden = g_BA(Variable(img_frequency)).cpu()\n",
    "            \n",
    "            # Clip back to the image using inverse SWT\n",
    "            img_reconstructed = pywt.iswt2([(img_hidden.squeeze().numpy(), None, None, None)], 'bior1.1')\n",
    "            \n",
    "            # Save the reconstructed image to the output directory\n",
    "            output_path = os.path.join(output_dir, file)\n",
    "            to_pil_image(img_reconstructed, mode='L').save(output_path)\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "input_dir = './test/LSWT_stego/class1'\n",
    "output_dir = './output_images/'\n",
    "reconstruct_images(input_dir, output_dir, g_BA, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
